{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forbidden-cleanup",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Multivariate SuSiE and ENLOC model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-warner",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-indication",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook aims to demonstrate a workflow of generating posterior inclusion probabilities (PIPs) from GWAS summary statistics using SuSiE regression and construsting SNP signal clusters from global eQTL analysis data obtained from multivariate SuSiE models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-chuck",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Methods overview\n",
    "\n",
    "This procedure assumes that molecular phenotype summary statistics and GWAS summary statistics are aligned and harmonized to have consistent allele coding (see [this module](../../misc/summary_stats_merger.html) for implementation details). Both molecular phenotype QTL and GWAS should be fine-mapped beforehand using mvSusiE or SuSiE. We further assume (and require) that molecular phenotype and GWAS data come from the same population ancestry. Violations from this assumption may not cause an error in the analysis computational workflow but the results obtained may not be valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-electronics",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-authority",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1) GWAS Summary Statistics with the following columns:\n",
    "    - chr: chromosome number\n",
    "    - bp: base pair position\n",
    "    - a1: effect allele\n",
    "    - a2: other allele\n",
    "    - beta: effect size\n",
    "    - se: standard error of beta\n",
    "    - z: z score\n",
    "\n",
    "2) eQTL data from multivariate SuSiE model with the following columns:\n",
    "    - chr: chromosome number\n",
    "    - bp: base pair position\n",
    "    - a1: effect allele\n",
    "    - a2: other allele\n",
    "    - pip: posterior inclusion probability\n",
    "\n",
    "3) LD correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-african",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-tunisia",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Intermediate files:\n",
    "\n",
    "1) GWAS PIP file with the following columns\n",
    "    - var_id\n",
    "    - ld_block \n",
    "    - snp_pip\n",
    "    - block_pip\n",
    "\n",
    "2) eQTL annotation file with the following columns\n",
    "    - chr\n",
    "    - bp\n",
    "    - var_id\n",
    "    - a1\n",
    "    - a2\n",
    "    - annotations, in the format: `gene:cs_num@tissue=snp_pip[cs_pip:cs_total_snps]`\n",
    "\n",
    "\n",
    "Final Outputs:\n",
    "\n",
    "1) Enrichment analysis result prefix.enloc.enrich.rst: estimated enrichment parameters and standard errors.\n",
    "\n",
    "2) Signal-level colocalization result prefix.enloc.sig.out: the main output from the colocalization analysis with the following format\n",
    "    - column 1: signal cluster name (from eQTL analysis)\n",
    "    - column 2: number of member SNPs\n",
    "    - column 3: cluster PIP of eQTLs\n",
    "    - column 4: cluster PIP of GWAS hits (without eQTL prior)\n",
    "    - column 5: cluster PIP of GWAS hits (with eQTL prior)\n",
    "    - column 6: regional colocalization probability (RCP)\n",
    "\n",
    "3) SNP-level colocalization result prefix.enloc.snp.out: SNP-level colocalization output with the following form at\n",
    "    - column 1: signal cluster name\n",
    "    - column 2: SNP name\n",
    "    - column 3: SNP-level PIP of eQTLs\n",
    "    - column 4: SNP-level PIP of GWAS (without eQTL prior)\n",
    "    - column 5: SNP-level PIP of GWAS (with eQTL prior)\n",
    "    - column 6: SNP-level colocalization probability\n",
    "\n",
    "4) Sorted list of colocalization signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-ancient",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Takes into consideration 3 situations: \n",
    "\n",
    "1) \"Major\" and \"minor\" alleles flipped\n",
    "\n",
    "2) Different strand but same variant\n",
    "\n",
    "3) Remove variants with A/T and C/G alleles due to ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-latitude",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-hands",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb merge \\\n",
    "    --cwd output \\\n",
    "    --eqtl-sumstats .. \\\n",
    "    --gwas-sumstats .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-camping",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb eqtl \\\n",
    "    --cwd output \\\n",
    "    --sumstats-file .. \\\n",
    "    --ld-region .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-vault",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb gwas \\\n",
    "    --cwd output \\\n",
    "    --sumstats-file .. \\\n",
    "    --ld-region .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-greensboro",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb enloc \\\n",
    "    --cwd output \\\n",
    "    --eqtl-pip .. \\\n",
    "    --gwas-pip .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-custody",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-internship",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.enrich.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-consequence",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.sig.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-statement",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "head enloc.snp.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-piece",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-african",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run mvenloc.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-intent",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efficient-schedule",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path\n",
    "parameter: container = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-sudan",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### Step 0: data formatting\n",
    "\n",
    "#### Extract common SNPS between the GWAS summary statistics and eQTL data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limited-summit",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[merger]\n",
    "# eQTL summary statistics as a list of RData\n",
    "parameter: eqtl_sumstats = path \n",
    "# GWAS summary stats in gz format\n",
    "parameter: gwas_sumstats = path \n",
    "input: eqtl_sumstats, gwas_sumstats\n",
    "output: f\"{cwd:a}/{eqtl_sumstats:bn}.standardized.gz\", f\"{cwd:a}/{gwas_sumstats:bn}.standardized.gz\"\n",
    "R: expand = \"${ }\"\n",
    "\n",
    "    ###\n",
    "    # functions\n",
    "    ###\n",
    "\n",
    "    allele.qc = function(a1,a2,ref1,ref2) {\n",
    "        # a1 and a2 are the first data-set\n",
    "        # ref1 and ref2 are the 2nd data-set\n",
    "        # Make all the alleles into upper-case, as A,T,C,G:\n",
    "            a1 = toupper(a1)\n",
    "            a2 = toupper(a2)\n",
    "            ref1 = toupper(ref1)\n",
    "            ref2 = toupper(ref2)\n",
    "        # Strand flip, to change the allele representation in the 2nd data-set\n",
    "        strand_flip = function(ref) {\n",
    "            flip = ref\n",
    "            flip[ref == \"A\"] = \"T\"\n",
    "            flip[ref == \"T\"] = \"A\"\n",
    "            flip[ref == \"G\"] = \"C\"\n",
    "            flip[ref == \"C\"] = \"G\"\n",
    "            flip\n",
    "        }\n",
    "        flip1 = strand_flip(ref1)\n",
    "        flip2 = strand_flip(ref2)\n",
    "        snp = list()\n",
    "        # Remove strand ambiguous SNPs (scenario 3)\n",
    "        snp[[\"keep\"]] = !((a1==\"A\" & a2==\"T\") | (a1==\"T\" & a2==\"A\") | (a1==\"C\" & a2==\"G\") | (a1==\"G\" & a2==\"C\"))\n",
    "        # Remove non-ATCG coding\n",
    "        snp[[\"keep\"]][ a1 != \"A\" & a1 != \"T\" & a1 != \"G\" & a1 != \"C\" ] = F\n",
    "        snp[[\"keep\"]][ a2 != \"A\" & a2 != \"T\" & a2 != \"G\" & a2 != \"C\" ] = F\n",
    "        # as long as scenario 1 is involved, sign_flip will return TRUE\n",
    "        snp[[\"sign_flip\"]] = (a1 == ref2 & a2 == ref1) | (a1 == flip2 & a2 == flip1)\n",
    "        # as long as scenario 2 is involved, strand_flip will return TRUE\n",
    "        snp[[\"strand_flip\"]] = (a1 == flip1 & a2 == flip2) | (a1 == flip2 & a2 == flip1)\n",
    "        # remove other cases, eg, tri-allelic, one dataset is A C, the other is A G, for example.\n",
    "        exact_match = (a1 == ref1 & a2 == ref2) \n",
    "        snp[[\"keep\"]][!(exact_match | snp[[\"sign_flip\"]] | snp[[\"strand_flip\"]])] = F\n",
    "        return(snp)\n",
    "    }\n",
    "\n",
    "    # Extract information from RData\n",
    "    eqtl.split = function(eqtl){\n",
    "      rows = length(eqtl)\n",
    "      chr = vector(length = rows)\n",
    "      pos = vector(length = rows)\n",
    "      a1 = vector(length = rows)\n",
    "      a2 = vector(length = rows)\n",
    "      for (i in 1:rows){\n",
    "        split1 = str_split(eqtl[i], \":\")\n",
    "        split2 = str_split(split1[[1]][2], \"_\")\n",
    "        chr[i]= split1[[1]][1]\n",
    "        pos[i] = split2[[1]][1]\n",
    "        a1[i] = split2[[1]][2]\n",
    "        a2[i] = split2[[1]][3]\n",
    "\n",
    "      }\n",
    "      eqtl.df = data.frame(eqtl,chr,pos,a1,a2)\n",
    "    }\n",
    "\n",
    "    remove.dup = function(df){\n",
    "      df = df %>% arrange(PosGRCh37, -N)\n",
    "      df = df[!duplicated(df$PosGRCh37),]\n",
    "      return(df)\n",
    "    }\n",
    "  \n",
    "    ###\n",
    "    # Code\n",
    "    ###\n",
    "    \n",
    "    # gene regions: \n",
    "    # 1 = ENSG00000203710\n",
    "    # 2 = ENSG00000064687\n",
    "    # 3 = ENSG00000203710\n",
    "    \n",
    "    # eqtl\n",
    "    gene.name = scan(${_input[0]:r}, what='character')\n",
    "\n",
    "    # initial filter of gwas variants that are in eqtl\n",
    "    gwas = gwas_sumstats\n",
    "    gwas_filter = gwas[which(gwas$id %in% var),]\n",
    "\n",
    "    # create eqtl df\n",
    "    eqtl.df = eqtl.split(eqtl$var)\n",
    "\n",
    "    # allele flip\n",
    "    f_gwas = gwas %>% filter(chr %in% eqtl.df$chr & PosGRCh37 %in% eqtl.df$pos)\n",
    "    eqtl.df.f = eqtl.df %>% filter(pos %in% f_gwas$PosGRCh37)\n",
    "\n",
    "    # check if there are duplicate pos\n",
    "    length(unique(f_gwas$PosGRCh37))\n",
    "\n",
    "    # multiple snps with same pos\n",
    "    dup.pos = f_gwas %>% group_by(PosGRCh37) %>% filter(n() > 1) \n",
    "\n",
    "    f_gwas = remove.dup(f_gwas)\n",
    "\n",
    "    qc = allele.qc(f_gwas$testedAllele, f_gwas$otherAllele, eqtl.df.f$a1, eqtl.df.f$a2)\n",
    "    keep = as.data.frame(qc$keep)\n",
    "    sign = as.data.frame(qc$sign_flip)\n",
    "    strand = as.data.frame(qc$strand_flip)\n",
    "\n",
    "    # sign flip\n",
    "    f_gwas$z[qc$sign_flip] = -1 * f_gwas$z[qc$sign_flip]\n",
    "    f_gwas$testedAllele[qc$sign_flip] = eqtl.df.f$a1[qc$sign_flip]\n",
    "    f_gwas$otherAllele[qc$sign_flip] = eqtl.df.f$a2[qc$sign_flip]\n",
    "\n",
    "    f_gwas$testedAllele[qc$strand_flip] = eqtl.df.f$a1[qc$strand_flip]\n",
    "    f_gwas$otherAllele[qc$strand_flip] = eqtl.df.f$a2[qc$strand_flip]\n",
    "\n",
    "    # remove ambigiuous \n",
    "    if ( sum(!qc$keep) > 0 ) {\n",
    "      eqtl.df.f = eqtl.df.f[qc$keep,]\n",
    "      f_gwas = f_gwas[qc$keep,]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-spirit",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Extract common SNPS between the summary statistics and LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "typical-outdoors",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_1, gwas_1 (filter LD file and sumstat file)]\n",
    "parameter: sumstat_file = path\n",
    "# LD and region information: chr, start, end, LD file\n",
    "paramter: ld_region = path\n",
    "input: sumstat_file, for_each = 'ld_region'\n",
    "output: f\"{cwd:a}/{sumstat_file:bn}_{region[0]}_{region[1]}_{region[2]}.z.rds\",\n",
    "        f\"{cwd:a}/{sumstat_file:bn}_{region[0]}_{region[1]}_{region[2]}.ld.rds\"\n",
    "R:\n",
    "    # FIXME: need to filter both ways for sumstats and for LD\n",
    "    # lds filtered\n",
    "  \n",
    "    eqtl_id = which(var %in% eqtl.df.f$eqtl)\n",
    "    ld_f = ld[eqtl_id, eqtl_id]\n",
    "\n",
    "    # ld missing\n",
    "    miss = which(is.na(ld_f), arr.ind=TRUE)\n",
    "    miss_r = unique(as.data.frame(miss)$row)\n",
    "    miss_c = unique(as.data.frame(miss)$col)\n",
    "\n",
    "    total_miss = unique(union(miss_r,miss_c))\n",
    "    # FIXME: LD should not have missing data if properly processed by our pipeline\n",
    "    # In the future we should throw an error when it happens\n",
    "\n",
    "    if (length(total_miss)!=0){\n",
    "    ld_f2 = ld_f[-total_miss,]\n",
    "    ld_f2 = ld_f2[,-total_miss]\n",
    "    dim(ld_f2)\n",
    "    }else{ld_f2 = ld_f}\n",
    "    \n",
    "    f_gwas.f = f_gwas %>% filter(id %in% eqtl_id.f$eqtl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-newton",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 1: fine-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "engaging-preserve",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_2, gwas_2 (finemapping)]\n",
    "# FIXME: RDS file should have included region information\n",
    "output: f\"{_input[0]:nn}.susieR.rds\", f\"{_input[0]:nn}.susieR_plot.rds\"\n",
    "R:\n",
    "    susie_results = susieR::susie_rss(z = f_gwas.f$z,R = ld_f2, check_prior = F)\n",
    "    susieR::susie_plot(susie_results,\"PIP\")\n",
    "    susie_results$z = f_gwas.f$z\n",
    "    susieR::susie_plot(susie_results,\"z_original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-render",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: fine-mapping results processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-mining",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Construct eQTL annotation file using eQTL SNP PIPs and credible sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-biography",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[eqtl_3 (create signal cluster using CS)]\n",
    "output: f\"{_input[0]:nn}.enloc_annot.gz\"\n",
    "R:\n",
    "    cs = eqtl[[\"sets\"]][[\"cs\"]][[\"L1\"]]\n",
    "    o_id = which(var %in% eqtl_id.f$eqtl)\n",
    "    pip = eqtl$pip[o_id]\n",
    "    eqtl_annot = cbind(eqtl_id.f, pip) %>% mutate(gene = gene.name,cluster = -1, cluster_pip = 0, total_snps = 0)\n",
    "\n",
    "    for(snp in cs){\n",
    "      eqtl_annot$cluster[snp] = 1\n",
    "      eqtl_annot$cluster_pip[snp] = eqtl[[\"sets\"]][[\"coverage\"]]\n",
    "       eqtl_annot$total_snps[snp] = length(cs)\n",
    "    }\n",
    "\n",
    "    eqtl_annot1 = eqtl_annot %>% filter(cluster != -1)%>% \n",
    "      mutate(annot = sprintf(\"%s:%d@=%e[%e:%d]\",gene,cluster,pip,cluster_pip,total_snps)) %>%\n",
    "      select(c(chr,pos,eqtl,a1,a2,annot))\n",
    "      \n",
    "    \n",
    "    # FIXME: repeats whole process (extracting+fine-mapping+cs creation) 3 times before this next step \n",
    "    eqtl_annot_comb = rbind(eqtl_annot3, eqtl_annot1, eqtl_annot2)\n",
    "\n",
    "    # FIXME: write to a zip file\n",
    "    write.table(eqtl_annot_comb, file = \"eqtl.annot.txt\", col.names = T, row.names = F, quote = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-concord",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Export GWAS PIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-protest",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[gwas_3 (format PIP into enloc GWAS input)]\n",
    "output: f\"{_input[0]:nn}.enloc_gwas.gz\"\n",
    "R:\n",
    "    gwas_annot1 = f_gwas.f %>% mutate(pip = susie_results$pip)\n",
    "    \n",
    "    # FIXME: repeat whole process (extracting common snps + fine-mapping) 3 times before the next steps\n",
    "    \n",
    "    gwas_annot_comb = rbind(gwas_annot3, gwas_annot1, gwas_annot2)\n",
    "    gwas_loc_annot = gwas_annot_comb %>% select(id, chr, PosGRCh37,z)\n",
    "    write.table(gwas_loc_annot, file = \"loc.gwas.txt\", col.names = F, row.names = F, quote = F)\n",
    "\n",
    "bash:    \n",
    "    perl format2torus.pl loc.gwas.txt > loc2.gwas.txt\n",
    "    \n",
    "R:\n",
    "    loc = data.table::fread(\"loc2.gwas.txt\")\n",
    "    loc = loc[[\"V2\"]]\n",
    "    \n",
    "    gwas_annot_comb2 = gwas_annot_comb %>% select(id, chr, PosGRCh37,pip)\n",
    "    gwas_annot_comb2 = cbind(gwas_annot_comb2, loc) %>% select(id, loc, pip)\n",
    "    \n",
    "    write.table(gwas_annot_comb2, file = \"gwas.pip.txt\", col.names = F, row.names = F, quote = F)\n",
    "\n",
    "bash:\n",
    "    perl format2torus.pl gwas.pip.txt | gzip --best > gwas.pip.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-armor",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: Colocalization with FastEnloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-sharing",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[enloc]\n",
    "# eQTL summary statistics as a list of RData\n",
    "# FIXME: to replace later\n",
    "parameter: eqtl_pip = path \n",
    "# GWAS summary stats in gz format\n",
    "parameter: gwas_pip = path \n",
    "input: eqtl_pip, gwas_pip\n",
    "output: f\"{cwd:a}/{eqtl_pip:bnn}.{gwas_pip:bnn}.xx.gz\"\n",
    "bash:\n",
    "    fastenloc -eqtl eqtl.annot.txt.gz -gwas gwas.pip.txt.gz\n",
    "    sort -grk6 prefix.enloc.sig.out | gzip --best > prefix.enloc.sig.sorted.gz\n",
    "    rm -f prefix.enloc.sig.out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
