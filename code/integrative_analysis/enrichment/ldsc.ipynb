{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Stratified LD Score Regression \n",
    "This notebook implements the pipepline of [S-LDSC](https://github.com/bulik/ldsc/wiki) for LD score and functional enrichment analysis. It is written by Anmol Singh (singh.anmol@columbia.edu), with input from Dr. Gao Wang.\n",
    "\n",
    "**FIXME: the initial draft is complete but pending Gao's review and documentation with minimal working example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Markdown"
   },
   "source": [
    "The pipeline is developed to integrate GWAS summary statistics data, annotation data, and LD reference panel data to compute functional enrichment for each of the epigenomic annotations that the user provides using the S-LDSC model. We will first start off with an introduction, instructions to set up, and the minimal working examples. Then the workflow code that can be run using SoS on any data will be at the end. \n",
    "\n",
    "## A brief review on Stratified LD score regression\n",
    "\n",
    "Here I briefly review LD Score Regression and what it is used for. For more in depth information on LD Score Regression please read the following three papers:\n",
    "\n",
    "1. \"LD Score regression distinguishes confounding from polygenicity in genome-wide association studies\" by Sullivan et al (2015)\n",
    "\n",
    "2. \"Partitioning heritability by functional annotation using genome-wide association summary statistics\" by Finucane et al (2015)\n",
    "\n",
    "3. \"Linkage disequilibrium–dependent architecture of human complex traits shows action of negative selection\" by Gazal et al (2017)\n",
    "\n",
    "As stated in Sullivan et al 2015, confounding factors and polygenic effects can cause inflated test statistics and other methods cannot distinguish between inflation from confounding bias and a true signal. LD Score Regression (LDSC) is a technique that aims to identify the impact of confounding factors and polygenic effects using information from GWAS summary statistics. \n",
    "\n",
    "This approach involves using regression to mesaure the relationship between Linkage Disequilibrium (LD) scores and test statistics of SNPs from the GWAS summary statistics. Variants in LD with a \"causal\" variant show an elevation in test statistics in association analysis proportional to their LD (measured by $r^2$) with the causal variant within a certain window size (could be 1 cM, 1kB, etc.). In contrast, inflation from confounders such as population stratification that occur purely from genetic drift will not correlate with LD. For a polygenic trait, SNPs with a high LD score will have more significant χ2 statistics on average than SNPs with a low LD score. Thus, if we regress the $\\chi^2$ statistics from GWAS against LD Score, the intercept minus one is an estimator of the mean contribution of confounding bias to the inflation in the test statistics. The regression model is known as LD Score regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### LDSC model\n",
    "\n",
    "Under a polygenic assumption, in which effect sizes for variants are drawn independently from distributions with variance proportional to  $1/(p(1-p))$ where p is the minor allele frequency (MAF), the expected $\\chi^2$ statistic of variant j is:\n",
    "\n",
    "$$E[\\chi^2|l_j] = Nh^2l_j/M + Na + 1 \\quad (1)$$\n",
    "\n",
    "where $N$ is the sample size; $M$ is the number of SNPs, such that $h^2/M$ is the average heritability explained per SNP; $a$ measures the contribution of confounding biases, such as cryptic relatedness and population stratification; and $l_j = \\sum_k r^2_{jk}$ is the LD Score of variant $j$, which measures the amount of genetic variation tagged by $j$. A full derivation of this equation is provided in the Supplementary Note of Sullivan et al (2015). An alternative derivation is provided in Supplementary Note of Zhu and Stephens (2017) AoAS.\n",
    "\n",
    "From this we can see that LD Score regression can be used to compute SNP-based heritability for a phenotype or trait, from GWAS summary statistics and does not require genotype information like other methods such as REML do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Stratified LDSC\n",
    "\n",
    "Heritability is the proportion of phenotypic variation (VP) that is due to variation in genetic values (VG) and thus can tell us how much of the difference in observed phenotypes in a sample is due to difference in genetics in the sample. It can also be extended to analyze partitioned heritability for a phenotype/trait split over categories. \n",
    "\n",
    "For Partitioned Heritability or Stratified LD Score Regression (S-LDSC) more power is added to our analysis by leveraging LD Score information as well as using SNPs that haven't reached Genome Wide Significance to partition heritability for a trait over categories which many other methods do not do. \n",
    "\n",
    "\n",
    "S-LDSC relies on the fact that the $\\chi^2$ association statistic for a given SNP includes the effects of all SNPs tagged by this SNP meaning that in a region of high LD in the genome the given SNP from the GWAS represents the effects of a group of SNPs in that region.\n",
    "\n",
    "S-LDSC determines that a category of SNPs is enriched for heritability if SNPs with high LD to that category have more significant $\\chi^2$ statistics than SNPs with low LD to that category.\n",
    "\n",
    "Here, enrichment of a category is defined as the proportion of SNP heritability in the category divided by the proportion of SNPs in that category.\n",
    "\n",
    "More precisely, under a polygenic model, the expected $\\chi^2$ statistic of SNP $j$ is\n",
    "\n",
    "$$E[\\chi^2_j] = N\\sum_CT_Cl(j,C) + Na + 1 \\quad (2)$$\n",
    "\n",
    "where $N$ is sample size, C indexes categories, $ℓ(j, C)$ is the LD score of SNP j with respect to category $l(j,C) = \\sum_{k\\epsilon C} r^2_{jk}$, $a$ is a term that measures the contribution of confounding biases, and if the categories are disjoint, $\\tau_C$ is the per-SNP heritability in category $C$; if the categories overlap, then the per-SNP heritability of SNP j is $\\sum_{C:j\\epsilon C} \\tau_C$.  Equation 2 allows us to estimate $\\tau_C$ via a (computationally simple) multiple regression of $\\chi^2$ against $ℓ(j, C)$, for either a quantitative or case-control study. \n",
    "\n",
    "To see how these methods have been applied to real world data as well as a further discussion on methods and comparisons to other methods please read the three papers listed at the top of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LDSC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  make_annot\n",
      "  munge_sumstats_no_sign\n",
      "  munge_sumstats_sign\n",
      "  calc_ld_score\n",
      "  calc_enrichment\n",
      "\n",
      "Sections\n",
      "  make_annot:\n",
      "    Workflow Options:\n",
      "      --bed VAL (as str, required)\n",
      "                        path to bed file\n",
      "      --bim VAL (as str, required)\n",
      "                        path to bim file\n",
      "      --annot VAL (as str, required)\n",
      "                        name of output annotation file\n",
      "  munge_sumstats_no_sign: This option is for when the summary statistic file\n",
      "                        does not contain a signed summary statistic (Z or Beta).\n",
      "                        In this case,the program will calculate Z for you based\n",
      "                        on A1 being the risk allele\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output VAL (as str, required)\n",
      "                        path to output file\n",
      "  munge_sumstats_sign:  This option is for when the summary statistic file does\n",
      "                        contain a signed summary statistic (Z or Beta)\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output VAL (as str, required)\n",
      "                        path to output file\n",
      "  calc_ld_score:        Calculate LD Scores **Make sure to delete SNP,CHR, and\n",
      "                        BP columns from annotation files if they are present\n",
      "                        otherwise this code will not work. Before deleting, if\n",
      "                        these columns are present, make sure that the annotation\n",
      "                        file is sorted.**\n",
      "    Workflow Options:\n",
      "      --bim VAL (as str, required)\n",
      "                        Path to bim file\n",
      "      --annot-file VAL (as str, required)\n",
      "                        Path to annotation File. Make sure to remove the SNP,\n",
      "                        CHR, and BP columns from the annotation file if present\n",
      "                        before running.\n",
      "      --output VAL (as str, required)\n",
      "                        name of output file\n",
      "      --snplist 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, remove the A1 and A2 columns\n",
      "                        for the Calculate LD Scores program\n",
      "  calc_enrichment:\n",
      "    Workflow Options:\n",
      "      --sumstats VAL (as str, required)\n",
      "                        Path to Summary statistics File\n",
      "      --ref-ld VAL (as str, required)\n",
      "                        Path to Reference LD Scores Files (Base Annotation +\n",
      "                        Annotation you want to analyze, format like minimal\n",
      "                        working example)\n",
      "      --w-ld VAL (as str, required)\n",
      "                        Path to LD Weight Files (Format like minimal working\n",
      "                        example)\n",
      "      --frq-file VAL (as str, required)\n",
      "                        path to frequency files (Format like minimal working\n",
      "                        example)\n",
      "      --output VAL (as str, required)\n",
      "                        Output name\n"
     ]
    }
   ],
   "source": [
    "!sos run LDSC_Code.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Make Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[make_annot]\n",
    "\n",
    "# Make Annotated Bed File\n",
    "\n",
    "# path to bed file\n",
    "parameter: bed = str \n",
    "#path to bim file\n",
    "parameter: bim = str\n",
    "#name of output annotation file\n",
    "parameter: annot = str\n",
    "bash: expand = True\n",
    "    make_annot.py --bed-file {bed} --bimfile {bim} --annot-file {annot}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Munge Summary Statistics (Option 1: No Signed Summary Statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#This option is for when the summary statistic file does not contain a signed summary statistic (Z or Beta). \n",
    "#In this case,the program will calculate Z for you based on A1 being the risk allele\n",
    "[munge_sumstats_no_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: expand = True\n",
    "    munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output} --a1-inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Munge Summary Statistics (Option 2: No Signed Summary Statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This option is for when the summary statistic file does contain a signed summary statistic (Z or Beta)\n",
    "[munge_sumstats_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: expand = True\n",
    "    munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate LD Scores\n",
    "\n",
    "**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate LD Scores\n",
    "#**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**\n",
    "[calc_ld_score]\n",
    "\n",
    "#Path to bim file\n",
    "parameter: bim = str\n",
    "#Path to annotation File. Make sure to remove the SNP, CHR, and BP columns from the annotation file if present before running.\n",
    "parameter: annot_file = str\n",
    "#name of output file\n",
    "parameter: output = str\n",
    "#path to Hapmap3 SNPs file, remove the A1 and A2 columns for the Calculate LD Scores program \n",
    "parameter: snplist = \"w_hm3.snplist\"\n",
    "\n",
    "bash: expand = True\n",
    "    ldsc.py --bfile {bim} --l2 --ld-wind-cm 1 --annot {annot_file} --thin-annot --out {output} --print-snps {snplist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate Functional Enrichment using Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate Enrichment Scores for Functional Annotations\n",
    "[calc_enrichment]\n",
    "\n",
    "#Path to Summary statistics File\n",
    "parameter: sumstats = str\n",
    "#Path to Reference LD Scores Files (Base Annotation + Annotation you want to analyze, format like minimal working example)\n",
    "parameter: ref_ld = str\n",
    "#Path to LD Weight Files (Format like minimal working example)\n",
    "parameter: w_ld = str\n",
    "#path to frequency files (Format like minimal working example)\n",
    "parameter: frq_file = str\n",
    "#Output name\n",
    "parameter: output = str\n",
    "\n",
    "bash: expand = True\n",
    "    ldsc.py --h2 {sumstats} --ref-ld-chr {ref_ld} --w-ld-chr {w_ld} --overlap-annot --frqfile-chr {frq_file} --out {output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
