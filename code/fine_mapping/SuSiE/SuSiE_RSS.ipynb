{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Fine-mapping with SuSiE RSS model\n",
    "\n",
    "This notebook mainly responsible for a matrixs of RSS using both mvsusie and a loop of uni_susie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "3. GWAS summary statistics input `z` and `R`. We assume `z` scores have been computed after removal of covariates `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "1. A recipe file documenting the path to\n",
    "\n",
    "1.1. A list of analysis_unit_list generated from Meta_Analysis step for each gene.\n",
    "\n",
    "    Each line of the index record the name of 1 RDS file, containing a list with bhat and sbhat object matrixs, with dimension = (number of snps*number of theme) \n",
    "    \n",
    "1.2.The path to a residual corr file from meta_analysis step [FIXME: Specified resid_corr for each gene to be added in the future]\n",
    "\n",
    "1.3. 3 col each record the path to a prior file from meta_analysis step.\n",
    "\n",
    "2. LD Recipe: a three colnums table with Theme as each of the Theme_prefix and other columns =  ld_file_prefix,   ld_file_surfix\n",
    "\n",
    "Only SNPS presented in both the LD matrixs and the sumstat rds will be analysis. \n",
    "In unisusie_rss, each of theme will use the corresponding ld file\n",
    "In mvsusie_rss, the last row will be used.\n",
    "\n",
    "The ld_prefix and ld_surfix are such that paste0(ld_file_prefix,gene_ID,ld_file_surfix) generate the path to each ld         matrix for each genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis unit we output:\n",
    "\n",
    "1. Analysis results in RDS format: A mvsusie Model\n",
    "2. A vcf file with selected snps\n",
    "        ES:PIP:CS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "import pandas as pd\n",
    "# Reciepe\n",
    "parameter: recipe = path(\"./\")\n",
    "#file_inv = pd.read_csv(recipe, sep = \"\\t\")\n",
    "parameter: merged_analysis_unit = path#(file_inv[\"merged_analysis_unit\"].values.tolist()[0])\n",
    "#parameter: resid_cor = path(file_inv[\"resid_corr\"].values.tolist()[0])\n",
    "parameter: Theme_prefix = str #file_inv[\"Theme_prefix\"].values.tolist()[0]\n",
    "## LD Recipe: a three colnums table with n_themes rows, as only 1 LD is required for each gene and each theme for uni_susie_RSS, columns =  ld_file_prefix, ld_file_surfix, Theme\n",
    "parameter: LD_Recipe = path\n",
    "## The snp with pip > criterior will be reported\n",
    "parameter: pip_criterior = 0.1\n",
    "#parameter: prior = path(file_inv[\"prior\"].values.tolist()[0])\n",
    "## data file suffix\n",
    "parameter: data_suffix = \"\"\n",
    "#\n",
    "## An identifier for your run of analysis\n",
    "parameter: name = Theme_prefix\n",
    "#\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(merged_analysis_unit).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = regions\n",
    "## Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "## Containers that contains the necessary packages\n",
    "parameter: container = \"/mnt/mfs/statgen/containers/twas_latest.sif\"\n",
    "## Only 1 LD for each gene is required for each analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_1,summary_stats_preprocessing]\n",
    "parameter: ld_type = 'original'\n",
    "parameter: bhat = \"bhat\"\n",
    "parameter: sbhat = \"sbhat\"\n",
    "input: genes, group_by = 1\n",
    "output: processed = f'{wd:a}/preprocessed/{_input:b}'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    dat = readRDS(${_input:r})\n",
    "    if(is.null(dat$Z)){\n",
    "    dat$Z = dat$${bhat}/dat$${sbhat}\n",
    "      }\n",
    "    gene_id = read.table(text = \"${_input:bnn}\", sep = \"_\")\n",
    "    gene_id = gene_id[,ncol(gene_id)][[1]]\n",
    "    ld.table = read_delim(\"${LD_Recipe}\" , \"\\t\")%>%mutate(ld.path = paste0(ld_file_prefix, gene_id ,ld_file_surfix )) \n",
    "    rownames(ld.table) = ld.table$Theme\n",
    "    ld.file = ld.table[nrow(ld.table),]\n",
    "    dat$ld.file = ld.file\n",
    "    dat$ld.table = ld.table\n",
    "    saveRDS(dat, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_2,MvSuSiE_summary_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "parameter: max_iter = 10\n",
    "parameter: ld_type = 'original'\n",
    "parameter: bhat = \"bhat\"\n",
    "parameter: sbhat = \"sbhat\"\n",
    "parameter: resid_cor = path#(file_inv[\"resid_corr\"].values.tolist()[0])\n",
    "parameter: prior = path#(file_inv[\"prior\"].values.tolist()[0])\n",
    "input: output_from(\"summary_stats_preprocessing\")\n",
    "output: f'{wd:a}/{_input:bnn}.LD{ld_type}{resid_cor:bnx}.mvsusierss.model.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container\n",
    "    get_prior_indices <- function(Z, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      z_names = colnames(Z)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(z_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(z_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(z_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    library(mvsusieR)\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "    dat = readRDS(${_input:r})\n",
    "    gene_id = \"${_input:bnn}\"\n",
    "    resid_cor = ${resid_cor:r}\n",
    "    V = readRDS(resid_cor)\n",
    "    prior = readRDS(${prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), \n",
    "                                        include_indices = get_prior_indices(dat$Z, prior$U[[1]]), \n",
    "                                        max_mixture_len=-1)\n",
    "    if(\"${ld_type}\" == 'original'){\n",
    "        R = readRDS(dat$ld.file$ld.path)\n",
    "    }else if(\"${ld_type}\" == 'remove_cov'){\n",
    "        R = dat$LD\n",
    "    }\n",
    "  \n",
    "    ## Remove the NA SNPs in R, assuming all NA = 0\n",
    "    R[is.na(R)] = 0\n",
    "    \n",
    "    ## Remove duplicated in Z\n",
    "    dat$Z = dat$Z[!duplicated(dat$snps),]\n",
    "    dat$snps = dat$snps[!duplicated(dat$snps)]\n",
    "    \n",
    "    # Retaining only the overlapping snps\n",
    "\n",
    "    R = R[which(rownames(R)%in%dat$snps),which(colnames(R)%in%dat$snps)]\n",
    "    dat$Z = dat$Z[which(dat$snps%in%rownames(R)),]\n",
    "    dat$snps = dat$snp[which(dat$snps%in%rownames(R))]\n",
    "\n",
    "\n",
    "    ## Initiate the computation  \n",
    "    st = proc.time()\n",
    "    mv_res = mvsusieR::mvsusie_rss(dat$Z, R, L=${max_L}, \n",
    "                                   prior_variance=prior, residual_variance=V, \n",
    "                                   precompute_covariances=T, compute_objective=T, \n",
    "                                   estimate_prior_variance=T, estimate_prior_method='EM',\n",
    "                                   max_iter = ${max_iter}, n_thread=1)\n",
    "    mv_res$time = proc.time() - st\n",
    "    #if(mv_res$convergence$converged == FALSE){\n",
    "    #    stop('Fail to converge.')\n",
    "    #}\n",
    "    mv_res$cs_corr = susieR:::get_cs_correlation(mv_res, Xcorr=R)\n",
    "  \n",
    "    # Get list of cs snps\n",
    "    mv_output = mv_res\n",
    "  \n",
    "    saveRDS(mv_res, ${_output[0]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_3,MvSuSiE_summary_stats_analysis_2]\n",
    "input:  group_by = 1\n",
    "output:    f'{_input:nn}.result.vcf.bgz'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:n}.stdout\", stderr = f\"{_output[0]:n}.stderr\"\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "    mv_res = readRDS(${_input:r})\n",
    "    ## Define create_vcf function\n",
    "           create_vcf = function (chrom, pos, nea, ea, snp = NULL, ea_af = NULL, effect = NULL, \n",
    "        se = NULL, pval = NULL, name = NULL,cs = NULL, pip = NULL) \n",
    "    {\n",
    "        stopifnot(length(chrom) == length(pos))\n",
    "        if (is.null(snp)) {\n",
    "            snp <- paste0(chrom, \":\", pos)\n",
    "        }\n",
    "        snp <- paste0(chrom, \":\", pos)\n",
    "        nsnp <- length(chrom)\n",
    "        gen <- list()\n",
    "        ## Setupt data content for each sample column\n",
    "        if (!is.null(ea_af)) \n",
    "            gen[[\"AF\"]] <- matrix(ea_af, nsnp)\n",
    "        if (!is.null(effect)) \n",
    "            gen[[\"ES\"]] <- matrix(effect, nsnp)\n",
    "        if (!is.null(se)) \n",
    "            gen[[\"SE\"]] <- matrix(se, nsnp)\n",
    "        if (!is.null(pval)) \n",
    "            gen[[\"LP\"]] <- matrix(-log10(pval), nsnp)\n",
    "        if (!is.null(cs)) \n",
    "            gen[[\"CS\"]] <- matrix(cs, nsnp)\n",
    "        if (!is.null(pip)) \n",
    "            gen[[\"PIP\"]] <- matrix(pip, nsnp)\n",
    "        gen <- S4Vectors::SimpleList(gen)\n",
    "        \n",
    "      ## Setup snps info for the fix columns\n",
    "        gr <- GenomicRanges::GRanges(chrom, IRanges::IRanges(start = pos, \n",
    "            end = pos + pmax(nchar(nea), nchar(ea)) - 1, names = snp))\n",
    "         coldata <- S4Vectors::DataFrame(Studies = name, row.names = name)\n",
    "    ## Setup header informations\n",
    "        hdr <- VariantAnnotation::VCFHeader(header = IRanges::DataFrameList(fileformat = S4Vectors::DataFrame(Value = \"VCFv4.2\", \n",
    "            row.names = \"fileformat\")), sample = name)\n",
    "        VariantAnnotation::geno(hdr) <- S4Vectors::DataFrame(Number = c(\"A\", \n",
    "            \"A\", \"A\", \"A\", \"A\", \"A\"), Type = c(\"Float\", \"Float\", \n",
    "            \"Float\", \"Float\", \"Float\", \"Float\"), Description = c(\"Effect size estimate relative to the alternative allele\", \n",
    "            \"Standard error of effect size estimate\", \"-log10 p-value for effect estimate\",  \n",
    "            \"Alternate allele frequency in the association study\",\n",
    "            \"The CS this variate are captured, 0 indicates not in any cs\", \"The posterior inclusion probability to a CS\"), \n",
    "            row.names = c(\"ES\", \"SE\", \"LP\", \"AF\", \"CS\", \"PIP\"))\n",
    "      ## Save only the meta information in the sample columns \n",
    "        VariantAnnotation::geno(hdr) <- subset(VariantAnnotation::geno(hdr), \n",
    "            rownames(VariantAnnotation::geno(hdr)) %in% names(gen))\n",
    "      ## Save VCF \n",
    "        vcf <- VariantAnnotation::VCF(rowRanges = gr, colData = coldata, \n",
    "            exptData = list(header = hdr), geno = gen)\n",
    "        VariantAnnotation::alt(vcf) <- Biostrings::DNAStringSetList(as.list(ea))\n",
    "        VariantAnnotation::ref(vcf) <- Biostrings::DNAStringSet(nea)\n",
    "      ## Add fixed values\n",
    "        VariantAnnotation::fixed(vcf)$FILTER <- \"PASS\"\n",
    "          return(sort(vcf))\n",
    "        }\n",
    "    \n",
    "    # Get list of cs snps\n",
    "    mv_output_snps = tibble( snps =  mv_res$variable_names[which(mv_res$pip > 0)], snps_index = which((mv_res$pip > 0))  )\n",
    "    mv_output_snps = mv_output_snps%>%mutate( cs = map(snps_index,~which(mv_res$sets$cs %in% .x))%>%as.numeric%>%replace_na(0),\n",
    "                             pip = map_dbl(snps_index,~(mv_res$pip[.x])),\n",
    "                     chr = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = T)$V1),\n",
    "                     pos_alt_ref = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = TRUE)$V2),\n",
    "                     pos = map_dbl(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE)$V1),\n",
    "                     alt = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V2),\n",
    "                     ref = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V3))\n",
    "    \n",
    "    effect_mtr = mv_res$coef[mv_output_snps$snps_index+1,]\n",
    "    colnames(effect_mtr) = mv_res$condition_names\n",
    "    rownames(effect_mtr) = mv_output_snps$snps\n",
    "    cs_mtr = effect_mtr\n",
    "    for(i in 1:nrow(cs_mtr)) cs_mtr[i,] =  mv_output_snps$cs[[i]]  \n",
    "    pip_mtr = effect_mtr\n",
    "    for(i in 1:nrow(pip_mtr)) pip_mtr[i,] =  mv_output_snps$pip[[i]]  \n",
    "\n",
    "    output_vcf = create_vcf(\n",
    "           chrom = mv_output_snps$chr,\n",
    "            pos = mv_output_snps$pos,\n",
    "            ea = mv_output_snps$alt,\n",
    "            nea = mv_output_snps$ref,\n",
    "            effect = effect_mtr ,\n",
    "            pip = pip_mtr,\n",
    "            cs = cs_mtr,\n",
    "            name = colnames(effect_mtr)\n",
    "              )\n",
    "  \n",
    "    saveRDS(mv_output_snps, \"${_output[0]:nn}.rds\")\n",
    "    VariantAnnotation::writeVcf(output_vcf,${_output[0]:nr},index = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_4,MvSuSiE_summary_stats_analysis_3]\n",
    "input: group_by = \"all\"\n",
    "output: f'{wd}/{Theme_prefix}.mvsusie_rss.output_list.txt'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"output_vcf\" : [$[_input:ar,]]}).to_csv(\"$[_output]\",index = False ,header = False, sep = \"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Univariate SuSiE RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_5,UniSuSiE_summary_stats_analysis_1]\n",
    "parameter: max_L = 10\n",
    "parameter: ld_type = 'original'\n",
    "parameter: bhat = \"bhat\"\n",
    "parameter: sbhat = \"sbhat\"\n",
    "input: output_from(\"summary_stats_preprocessing\")[\"processed\"]\n",
    "output: uni_rds = f'{wd:a}/{_input:bnn}.LD{ld_type}.unisusierss.model.rds',\n",
    "        uni_vcf = f'{wd:a}/{_input:bnn}.LD{ld_type}.unisusierss.vcf.bgz'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:n}.stdout\", stderr = f\"{_output[0]:n}.stderr\"\n",
    "    library(\"susieR\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "  \n",
    "     ## Define create_vcf function\n",
    "           create_vcf = function (chrom, pos, nea, ea, snp = NULL, ea_af = NULL, effect = NULL, \n",
    "        se = NULL, pval = NULL, name = NULL,cs = NULL, pip = NULL) \n",
    "    {\n",
    "        stopifnot(length(chrom) == length(pos))\n",
    "        if (is.null(snp)) {\n",
    "            snp <- paste0(chrom, \":\", pos)\n",
    "        }\n",
    "        snp <- paste0(chrom, \":\", pos)\n",
    "        nsnp <- length(chrom)\n",
    "        gen <- list()\n",
    "        ## Setupt data content for each sample column\n",
    "        if (!is.null(ea_af)) \n",
    "            gen[[\"AF\"]] <- matrix(ea_af, nsnp)\n",
    "        if (!is.null(effect)) \n",
    "            gen[[\"ES\"]] <- matrix(effect, nsnp)\n",
    "        if (!is.null(se)) \n",
    "            gen[[\"SE\"]] <- matrix(se, nsnp)\n",
    "        if (!is.null(pval)) \n",
    "            gen[[\"LP\"]] <- matrix(-log10(pval), nsnp)\n",
    "        if (!is.null(cs)) \n",
    "            gen[[\"CS\"]] <- matrix(cs, nsnp)\n",
    "        if (!is.null(pip)) \n",
    "            gen[[\"PIP\"]] <- matrix(pip, nsnp)\n",
    "        gen <- S4Vectors::SimpleList(gen)\n",
    "        \n",
    "      ## Setup snps info for the fix columns\n",
    "        gr <- GenomicRanges::GRanges(chrom, IRanges::IRanges(start = pos, \n",
    "            end = pos + pmax(nchar(nea), nchar(ea)) - 1, names = snp))\n",
    "         coldata <- S4Vectors::DataFrame(Studies = name, row.names = name)\n",
    "    ## Setup header informations\n",
    "        hdr <- VariantAnnotation::VCFHeader(header = IRanges::DataFrameList(fileformat = S4Vectors::DataFrame(Value = \"VCFv4.2\", \n",
    "            row.names = \"fileformat\")), sample = name)\n",
    "        VariantAnnotation::geno(hdr) <- S4Vectors::DataFrame(Number = c(\"A\", \n",
    "            \"A\", \"A\", \"A\", \"A\", \"A\"), Type = c(\"Float\", \"Float\", \n",
    "            \"Float\", \"Float\", \"Float\", \"Float\"), Description = c(\"Effect size estimate relative to the alternative allele\", \n",
    "            \"Standard error of effect size estimate\", \"-log10 p-value for effect estimate\",  \n",
    "            \"Alternate allele frequency in the association study\",\n",
    "            \"The CS this variate are captured, 0 indicates not in any cs\", \"The posterior inclusion probability to a CS\"), \n",
    "            row.names = c(\"ES\", \"SE\", \"LP\", \"AF\", \"CS\", \"PIP\"))\n",
    "      ## Save only the meta information in the sample columns \n",
    "        VariantAnnotation::geno(hdr) <- subset(VariantAnnotation::geno(hdr), \n",
    "            rownames(VariantAnnotation::geno(hdr)) %in% names(gen))\n",
    "      ## Save VCF \n",
    "        vcf <- VariantAnnotation::VCF(rowRanges = gr, colData = coldata, \n",
    "            exptData = list(header = hdr), geno = gen)\n",
    "        VariantAnnotation::alt(vcf) <- Biostrings::DNAStringSetList(as.list(ea))\n",
    "        VariantAnnotation::ref(vcf) <- Biostrings::DNAStringSet(nea)\n",
    "      ## Add fixed values\n",
    "        VariantAnnotation::fixed(vcf)$FILTER <- \"PASS\"\n",
    "          return(sort(vcf))\n",
    "        }\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    gene_id = \"${_input:bnn}\"\n",
    "\n",
    "    ## Initiate the computation  \n",
    "    st = proc.time()\n",
    "    susie_list = list()\n",
    "    for (i in 1:ncol(dat$Z)) {\n",
    "          ## Retaining only the overlapping snps\n",
    "    ld = readRDS(dat$ld.table[colnames(dat$Z)[i],]$ld.path)\n",
    "    int_snps = intersect(rownames(ld),dat$snps)\n",
    "    ld = ld[which(rownames(ld)%in%int_snps),which(colnames(ld)%in%int_snps)]\n",
    "    ld[is.na(ld)] = 0\n",
    "    Z = dat$Z[which(dat$snps%in%int_snps),i]\n",
    "    snps = dat$snps[which(dat$snps%in%int_snps)]\n",
    "      susie_list[[i]] = susie_rss(Z, ld)\n",
    "      susie_list[[i]]$conditions_name = colnames(dat$Z)[[i]]\n",
    "      susie_list[[i]]$variable_name = snps\n",
    "      }\n",
    "\n",
    "  \n",
    "      susie_tb_ls = list()\n",
    "    for (i in 1:length(susie_list)){\n",
    "        susie_tb = tibble( snps =  susie_list[[i]]$variable_name[which( susie_list[[i]]$pip >= 0)], snps_index = which(( susie_list[[i]]$pip >= 0))  )\n",
    "        susie_tb_ls[[i]]= susie_tb%>%mutate( cs = map(snps_index,~which( susie_list[[i]]$sets$cs %in% .x))%>%as.numeric%>%replace_na(0),\n",
    "                                 pip = map_dbl(snps_index,~( susie_list[[i]]$pip[.x])),\n",
    "                                 coef = map_dbl(snps_index,~(coef.susie( susie_list[[i]])[.x+1])))\n",
    "        }\n",
    "    for(i in 2:length(susie_tb_ls)){susie_tb_ls[[i]] = full_join(susie_tb_ls[[i-1]],susie_tb_ls[[i]], by = \"snps\") }\n",
    "    m = c(\"cs\",\"pip\",\"coef\")    \n",
    "    output = list()\n",
    "    for(i in m){\n",
    "    output[[i]] = susie_tb_ls[[length(susie_tb_ls)]]%>%select(contains(i))%>%as.matrix\n",
    "    }\n",
    "    snps_tb = susie_tb_ls[[length(susie_tb_ls)]]%>%mutate(\n",
    "                         chr = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = T)$V1),\n",
    "                         pos_alt_ref = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = TRUE)$V2),\n",
    "                         pos = map_dbl(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE)$V1),\n",
    "                         alt = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V2),\n",
    "                         ref = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V3))\n",
    "  \n",
    "    output_vcf = create_vcf(\n",
    "               chrom = snps_tb$chr,\n",
    "                pos = snps_tb$pos,\n",
    "                ea = snps_tb$alt,\n",
    "                nea = snps_tb$ref,\n",
    "                effect = output$coef ,\n",
    "                pip = output$pip,\n",
    "                cs = output$cs,\n",
    "                name = colnames(dat$Z)\n",
    "                  )\n",
    "  \n",
    "      \n",
    "    saveRDS(susie_list, ${_output[0]:r})\n",
    "    VariantAnnotation::writeVcf(output_vcf,${_output[1]:nr},index = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[Fine_mapping_6,UniSuSiE_summary_stats_analysis_2]\n",
    "input: output_from(\"UniSuSiE_summary_stats_analysis_1\")[\"uni_vcf\"], group_by = \"all\"\n",
    "output: f'{wd}/{Theme_prefix}.unisusie_rss.output_list.txt'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"output_vcf\" : [$[_input:ar,]]}).to_csv(\"$[_output]\",index = False ,header = False, sep = \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
