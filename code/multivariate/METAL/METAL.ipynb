{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "owned-fortune",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Meta-analysis with METAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-dover",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "METAT is a command line tool, takes in a script that documenting the input sumstat files, the field of each of those sumstat input file, and then the end of scipt.\n",
    "\n",
    "METAL analysis is enssentially a weighted sum of Z score, therefore the input of snps from each chrm can be processed seperately. To make sure the same region was analysis, the input of this workflow shall be a list of path to the sumstat, join by \" \" to be analyzed at once.\n",
    "\n",
    "Also, The scheme of weighting at the moment is set to be standard error, changing it to sample size would require the upstream input have a columns named sample size, which they dont have it yet.\n",
    "\n",
    "At the moment, the AVERAGEFREQ, MINMAXFREQ, and GENOMICCONTROL are by default set to off, turning on each of the option require additional input from upstream file.\n",
    "\n",
    "The output file name of the seconde step will by default contains a 1 linking the desinateted prefix and surfix, which lead to the f'{wd}/{name}1.METAL.txt' file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-israeli",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: sumstat_list_path = path\n",
    "parameter: variant_id = 'variant_id'\n",
    "parameter: Sample_size = 'N'\n",
    "parameter: ALLELE = 'alt ref'\n",
    "parameter: FREQ   = 'EFFECT_ALLELE_FREQ'\n",
    "parameter: Beta = 'beta'\n",
    "parameter: SE = 'se'\n",
    "parameter: PVAL   = 'pval'\n",
    "parameter: wd = path\n",
    "parameter: SCHEME = 'STDERR'\n",
    "parameter: AVERAGEFREQ = \"OFF\"\n",
    "parameter: MINMAXFREQ  = \"OFF\"\n",
    "parameter: GENOMICCONTROL  = \"OFF\"\n",
    "parameter: container = str\n",
    "import pandas as pd\n",
    "\n",
    "sumstat_list = pd.read_csv(sumstat_list_path, sep = \"\\t\")\n",
    "sumstat_inv = sumstat_list.values.tolist()\n",
    "name = \"-\".join(sumstat_list.columns.values[1:len(sumstat_list.columns.values)].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-jackson",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step.1 Script generation\n",
    "The METAL script contains three sections, the first is the analysis parameters, the second is the inputs files, and the third is the ending of script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-orchestra",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL_1,generate_METAL_script]\n",
    "input:  for_each = \"sumstat_inv\"\n",
    "output: METAL_script = f'{wd:a}/{name}.{_sumstat_inv[0]}.METAL_script.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "        echo '\n",
    "        # Meta-analysis weighted by:\n",
    "        SCHEME   $[SCHEME]\n",
    "        \n",
    "        # Whether do genomics control\n",
    "        GENOMICCONTROL $[GENOMICCONTROL]\n",
    "        \n",
    "        # Whether do AVERAGEFREQ or MINMAXFREQ control\n",
    "        AVERAGEFREQ $[AVERAGEFREQ]\n",
    "        MINMAXFREQ $[MINMAXFREQ] \n",
    "        OUTFILE $[wd:a]/$[name].$[_sumstat_inv[0]]. .METAL.txt' > $[_output]\n",
    "\n",
    "        for i in $[\" \".join(_sumstat_inv[1:len(_sumstat_inv)])] ; do \n",
    "        echo \"     \n",
    "        MARKER   $[variant_id]\n",
    "        WEIGHT   $[Sample_size]\n",
    "        ALLELE   $[ALLELE]\n",
    "        #FREQ     $[FREQ]\n",
    "        EFFECT   $[Beta]\n",
    "        STDERR   $[SE]\n",
    "        PVAL     $[PVAL]\n",
    "        PROCESS  $i \" >> $[_output];\n",
    "        done \n",
    "        \n",
    "        echo '\n",
    "        ANALYZE' >> $[_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-measure",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 2. Metal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-substance",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL_2,Excute_METAL_script]\n",
    "input: group_with = \"sumstat_inv\"\n",
    "output: f'{wd}/{name}.{_sumstat_inv[0]}.1.METAL.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '24h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container\n",
    "       metal $[_input]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-alpha",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 3. Reformat the output so that they are in the same formmat as the non metaled one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-confidence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL_3,Output_reformatting]\n",
    "input: group_with = \"sumstat_inv\"\n",
    "output: f'{wd:a}/{name}.{_sumstat_inv[0]}.METAL.vcf.bgz',\n",
    "        sumstat = f'{wd:a}/{name}.{_sumstat_inv[0]}.METAL.txt'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '2h', mem = '55G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container \n",
    "        import pandas as pd\n",
    "        df = pd.read_csv($[_input:r],sep = \"\\t\")\n",
    "        df.columns = [\"variant_id\",\"alt\",\"ref\",\"beta\",\"se\",\"pval\",\"Direction\"]\n",
    "        df = df.assign(\n",
    "        pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0].split(\":\")[1])).assign(\n",
    "        chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0]))\n",
    "        df.to_csv(\"$[_output[1]]\",sep = \"\\t\",index = 0)\n",
    "\n",
    "R: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container \n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    ## Define a wrapper, modified from the gwasvcf packages, to create the vcf of needed.\n",
    "        create_vcf = function (chrom, pos, nea, ea, snp = NULL, ea_af = NULL, effect = NULL, \n",
    "        se = NULL, pval = NULL, n = NULL, ncase = NULL, name = NULL) \n",
    "    {\n",
    "        stopifnot(length(chrom) == length(pos))\n",
    "        if (is.null(snp)) {\n",
    "            snp <- paste0(chrom, \":\", pos)\n",
    "        }\n",
    "        snp <- paste0(chrom, \":\", pos)\n",
    "        nsnp <- length(chrom)\n",
    "        gen <- list()\n",
    "        ## Setupt data content for each sample column\n",
    "        if (!is.null(ea_af)) \n",
    "            gen[[\"AF\"]] <- matrix(ea_af, nsnp)\n",
    "        if (!is.null(effect)) \n",
    "            gen[[\"ES\"]] <- matrix(effect, nsnp)\n",
    "        if (!is.null(se)) \n",
    "            gen[[\"SE\"]] <- matrix(se, nsnp)\n",
    "        if (!is.null(pval)) \n",
    "            gen[[\"LP\"]] <- matrix(-log10(pval), nsnp)\n",
    "        if (!is.null(n)) \n",
    "            gen[[\"SS\"]] <- matrix(n, nsnp)\n",
    "        if (!is.null(ncase)) \n",
    "            gen[[\"NC\"]] <- matrix(ncase, nsnp)\n",
    "        gen <- S4Vectors::SimpleList(gen)\n",
    "        \n",
    "      ## Setup snps info for the fix columns\n",
    "        gr <- GenomicRanges::GRanges(chrom, IRanges::IRanges(start = pos, \n",
    "            end = pos + pmax(nchar(nea), nchar(ea)) - 1, names = snp))\n",
    "      ## Setup meta informations\n",
    "         coldata <- S4Vectors::DataFrame(Studies = name, row.names = name)\n",
    "        hdr <- VariantAnnotation::VCFHeader(header = IRanges::DataFrameList(fileformat = S4Vectors::DataFrame(Value = \"VCFv4.2\", \n",
    "            row.names = \"fileformat\")), sample = name)\n",
    "        VariantAnnotation::geno(hdr) <- S4Vectors::DataFrame(Number = c(\"A\", \n",
    "            \"A\", \"A\", \"A\", \"A\", \"A\"), Type = c(\"Float\", \"Float\", \n",
    "            \"Float\", \"Float\", \"Float\", \"Float\"), Description = c(\"Effect size estimate relative to the alternative allele\", \n",
    "            \"Standard error of effect size estimate\", \"-log10 p-value for effect estimate\", \n",
    "            \"Alternate allele frequency in the association study\", \n",
    "            \"Sample size used to estimate genetic effect\", \"Number of cases used to estimate genetic effect\"), \n",
    "            row.names = c(\"ES\", \"SE\", \"LP\", \"AF\", \"SS\", \"NC\"))\n",
    "      ## Save only the meta information in the sample columns \n",
    "        VariantAnnotation::geno(hdr) <- subset(VariantAnnotation::geno(hdr), \n",
    "            rownames(VariantAnnotation::geno(hdr)) %in% names(gen))\n",
    "      ## Save VCF values\n",
    "        vcf <- VariantAnnotation::VCF(rowRanges = gr, colData = coldata, \n",
    "            exptData = list(header = hdr), geno = gen)\n",
    "        VariantAnnotation::alt(vcf) <- Biostrings::DNAStringSetList(as.list(ea))\n",
    "        VariantAnnotation::ref(vcf) <- Biostrings::DNAStringSet(nea)\n",
    "      ## Write fixed values\n",
    "        VariantAnnotation::fixed(vcf)$FILTER <- \"PASS\"\n",
    "            return(sort(vcf))\n",
    "        }\n",
    "  \n",
    "        input = read_delim($[_output[1]:r],\"\\t\")\n",
    "        input_effect = input$beta\n",
    "        input_se = input$se\n",
    "        df = tibble(snps = input$variant_id)\n",
    "        df = df%>%mutate(    chr = map_dbl(snps,~read.table(text = .x,sep = \":\",as.is = T)$V1),\n",
    "                     pos_alt_ref = map_chr(snps,~read.table(text = .x,sep = \":\",as.is = TRUE)$V2),\n",
    "                     pos = map_dbl(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE)$V1),\n",
    "                     alt = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V3),\n",
    "                     ref = map_chr(pos_alt_ref,~read.table(text = .x,sep = \"_\",as.is = TRUE, colClass = \"character\")$V2))\n",
    "        vcf = create_vcf(\n",
    "           chrom = df$chr,\n",
    "            pos = df$pos,\n",
    "            ea = df$alt,\n",
    "            nea = df$ref,\n",
    "            effect = input_effect ,\n",
    "            se =  input_se,\n",
    "            name = \"$[name]\")\n",
    "      VariantAnnotation::writeVcf(vcf,$[_output[0]:nr],index = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-prize",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[METAL_4,recipe]\n",
    "input: output_from(\"METAL_3\")[\"sumstat\"],group_by = \"all\"\n",
    "output: f'{wd}/{name}.METAL_list.txt'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout' , container = container \n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame({\"#chr\" : pd.read_csv($[sumstat_list_path:r],sep = \"\\t\")[\"#chr\"].values.tolist()  ,  \"$[name]\"  : [$[_input:r,]] })\n",
    "        df.to_csv(\"$[_output]\",sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-pierre",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-episode",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
