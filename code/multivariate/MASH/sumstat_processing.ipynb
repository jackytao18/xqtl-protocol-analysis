{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-soviet",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Summary statistics formatting\n",
    "This notebook takes in more than one collections of sumstat text file,  to produce a collections of merged.rds per gene files that can served as the input of both MASH and MVSuSiE analysis.\n",
    "\n",
    "## Input\n",
    "1. a sumstat list with columns: \"#chr\", theme1, theme2, theme3, each cells not under #chr represent the path to 1 sumstat file(generated by yml generator)\n",
    "2. region_list:a table with columns: chr, start, end, gene_ID for partition\n",
    "## Output\n",
    "1. 23 merged sumstat file in txt format, 1 for each chrom\n",
    "2. merged sumstat file in rds format, 1 for each gene\n",
    "3. 2 file documenting 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde54a9-50a7-411f-bc04-2e677c603069",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/sumstat_processing.ipynb processing \\\n",
    "    --sumstat_inv `ls /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_celltypes_analysis/output/data_intergration/TensorQTL/*norminal.cis_long_table.merged.vcf.gz` \\\n",
    "    -n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f595c-f75d-47f7-899f-862deca12210",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-turkey",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# Path to work directory where output locates\n",
    "parameter: cwd = path(\"./output\")\n",
    "# Containers that contains the necessary packages\n",
    "parameter: container = ''\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Columns: \"#chr\", sumstat(merged.vcf.gz)\n",
    "parameter: sumstat_inv = paths\n",
    "parameter: name = f'{sumstat_inv[0]:b}'.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08906d3-8077-4705-90d5-144e10306a3d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[processing_1]\n",
    "input: sumstat_inv, group_by = 1\n",
    "output: f'{cwd:a}/RDS/{_input:bnnn}.merged_rds.list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    extract_data = function(vcfObj,keep_snp){\n",
    "        bhat = VariantAnnotation::geno(vcfObj)$STAT[keep_snp,]\n",
    "        sbhat = VariantAnnotation::geno(vcfObj)$SE[keep_snp,]\n",
    "        z = bhat/sbhat\n",
    "        snp = map_chr(rownames(z),~stringr::str_split(.x,pattern = \":\", n = 2 )[[1]][2])%>%unique\n",
    "        rownames(bhat) = snp\n",
    "        rownames(sbhat) = snp\n",
    "        rownames(z) = snp\n",
    "    return(list(\"bhat\" = bhat , \"sbhat\" = sbhat, \"Z\" = z, \"snp\" = snp ))}\n",
    "    vcfObj = VariantAnnotation::readVcf(\"${_input}\")\n",
    "    GENE = unique(VariantAnnotation::info(vcfObj)$GENE)%>%as.list()\n",
    "    info = VariantAnnotation::info(vcfObj)%>%as_tibble(rownames = \"ID\")\n",
    "    output_list = map(GENE, ~extract_data(vcfObj,info%>%filter(GENE %in% .x )%>%pull(ID)))\n",
    "    output_path = tibble(gene = GENE%>%unlist)%>%mutate(path = map_chr(GENE,~paste0(\"${_output:nn}.\",.x,\".rds\")) )\n",
    "    walk2(output_list,output_path$path,~.x%>%saveRDS(.y))\n",
    "    output_path%>%write_delim(\"${_output}\",\"\\t\",col_names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55824ed4-e2e8-484c-aaf5-517d8d1b7020",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[processing_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd:a}/{name}.merged_rds.list'\n",
    "bash: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    echo -e '#gene\\t#path' > ${_output}\n",
    "    cat ${_input:r} >> ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-investigation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[processing_1]\n",
    "input:  for_each = \"sumstat_inv\"\n",
    "output: f'{wd:a}/merge/{name}.{_sumstat_inv[0]}.merged.txt'\n",
    "task: trunk_workers = 1, trunk_size = 20, walltime = '4h',  mem = '6G', tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    library(\"dplyr\")\n",
    "    library(\"tibble\")\n",
    "    library(\"purrr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"stringr\")\n",
    "    ## Start\n",
    "    Theme = c('$[\"','\".join(theme)]')\n",
    "    dir = c('$[\"','\".join(_sumstat_inv[1:])]')\n",
    "    tb = tibble(Theme = Theme, dir = dir)%>%mutate(data = map(dir,~read_delim(.x,\"\\t\")%>%select(`$[chrom]`,$[pos],$[variant_id],$[beta],$[se])))\n",
    "    data = tb$data%>%reduce(inner_join, by = c(\"$[chrom]\",\"$[pos]\",\"$[variant_id]\"))%>%\n",
    "      rename_if(str_detect(names(.),\"$[beta]\"), ~paste0(\"$[beta]_\",Theme))%>%\n",
    "      rename_if(str_detect(names(.),\"$[se]\"), ~paste0(\"$[se]_\",Theme))\n",
    "    data%>%write_delim(\"$[_output]\",\" \")\n",
    "#[processing_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{wd:a}/merge/{name}_sumstat_list_per_chrom'\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"chr\" : sumstat_list[\"#chr\"], \"dir\" : _input})\n",
    "df.to_csv(_output,sep = \"\\t\",index = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-secretary",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[processing_3]\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: windows = 5000000\n",
    "input: for_each = \"regions\"\n",
    "output: f'{wd:a}/merge/RDS/{name}_{_regions[3]}.rds'\n",
    "task: trunk_workers = 1, trunk_size = 1, walltime = '12h',  mem = '10G', tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout',container = container\n",
    "    library(\"tibble\")\n",
    "    library(\"readr\")\n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"stringr\")\n",
    "    sumstat_list = read_delim(\"$[_input]\",\"\\t\")\n",
    "    sumstat_path = (sumstat_list%>%filter(chr == $[_regions[0]]))$dir\n",
    "    sumstat_ftr = read_delim(sumstat_path,delim = \" \" )%>%filter( `$[pos]` >=  $[_regions[1]] - $[windows], `$[pos]` <= $[_regions[1]] + $[windows])%>%mutate($[variant_id] = str_remove($[variant_id],\"chr\"))\n",
    "    output = list()\n",
    "    output$bhat = as.matrix(sumstat_ftr%>%select(contains(\"$[beta]\"))%>%rename_all(~str_replace(.,\"$[beta]_\",\"\")))\n",
    "    rownames(output$bhat) = (sumstat_ftr$$[variant_id])%>%unlist%>%as.character\n",
    "    output$sbhat = as.matrix(sumstat_ftr%>%select(contains(\"$[se]\"))%>%rename_all(~str_replace(.,\"$[se]_\",\"\")))\n",
    "    rownames(output$sbhat) = (sumstat_ftr$$[variant_id])%>%unlist%>%as.character\n",
    "    output$Z = output$bhat/output$sbhat\n",
    "    #keep_index = which(!is.na(output$Z) && !is.nan(output$Z) && is.finite(output$Z))\n",
    "    #output$bhat = output$bhat[keep_index]\n",
    "    #output$sbhat = output$sbhat[keep_index]\n",
    "    #output$Z = output$Z[keep_index]\n",
    "    output$snps = rownames(output$bhat)\n",
    "    output%>%saveRDS(\"$[_output]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694039a-163e-42d2-81ef-47007d1a89a6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[processing_4]\n",
    "input: group_by = \"all\"\n",
    "output: f'{wd:a}/merge/RDS/{name}.analysis_unit'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"analysis_unit\" : [$[_input:ar,]]}).to_csv(\"$[_output]\",index = False ,header = False, sep = \"t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
