{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# A multivariate EBNM approach for mixture multivariate distribution estimate\n",
    "\n",
    "This is a truncated version from the bioworkflow/mixture_prior analysis, the steps where mixture components were generated are removed to not duplicate with that of the mashr_flashr_workflow. \n",
    "\n",
    "\n",
    "An earlier version of the approach is outlined in Urbut et al 2019. This workflow implements a few improvements including using additional EBMF methods as well as the new `udr` package to fit the mixture model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview of approach\n",
    "\n",
    "1. A workflow step is provided to merge PLINK univariate association analysis results to RDS files for extracting effect estimate samples\n",
    "2. Estimated effects are analyzed by FLASH and PCA to extract patterns of sharing\n",
    "3. Estimate the weights for patterns extracted from previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To see the input requirements and output data formats, please [download a minimal working example here](https://drive.google.com/file/d/1838xUOQuWTszQ0WJGXNiJMszY05cw3RS/view?usp=sharing), and run the following:\n",
    "\n",
    "### Merge univariate results\n",
    "\n",
    "```\n",
    "sos run mixture_prior.ipynb merge \\\n",
    "    --analysis-units <FIXME> \\\n",
    "    --plink-sumstats <FIXME> \\\n",
    "    --name gtex_mixture\n",
    "```\n",
    "\n",
    "### Select and merge univariate effects\n",
    "\n",
    "```\n",
    "m=/path/to/data\n",
    "cd $m && ls *.rds | sed 's/\\.rds//g' > analysis_units.txt && cd -\n",
    "sos run mixture_prior.ipynb extract_effects \\\n",
    "        --analysis-units $m/analysis_units.txt \\\n",
    "        --datadir $m --name `basename $m`\n",
    "```\n",
    "\n",
    "### Perform mixture model fitting\n",
    "\n",
    "```\n",
    "sos run mixture_prior.ipynb ud \\\n",
    "    --datadir $m --name `basename $m` &> ed_$m.log\n",
    "sos run mixture_prior.ipynb ud --ud-method ted \\\n",
    "    --datadir $m --name `basename $m` &> ted_$m.log\n",
    "sos run mixture_prior.ipynb ed \\\n",
    "    --datadir $m --name `basename $m` &> bovy_$m.log\n",
    "```\n",
    "\n",
    "### Plot results\n",
    "\n",
    "```\n",
    "sos run mixture_prior.ipynb plot_U --model-data /path/to/mixture_model.rds --cwd output\n",
    "```\n",
    "\n",
    "Notice that for production use, each `sos run` command should be submitted to the cluster as a job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path('./output')\n",
    "# The filename prefix for output data\n",
    "parameter: mixture_components_dir = path\n",
    "parameter: name = str\n",
    "parameter: data = path\n",
    "parameter: mixture_components = ['flash', 'flash_nonneg', 'pca', 'canonical']\n",
    "parameter: job_size = 1# Residual correlatoin file\n",
    "parameter: effect_model = \"EZ\"\n",
    "parameter: vhat = \"simple\"\n",
    "parameter: job_size = 1\n",
    "# Residual correlatoin (vhat) file\n",
    "parameter: resid_cor = file_target(f\"{mixture_components_dir:a}/{name}.{effect_model}.V_{vhat}.rds\")\n",
    "parameter: container = 'gaow/twas'\n",
    "fail_if(not (resid_cor.is_file() or resid_cor == path('.')), msg = f'Cannot find ``{resid_cor}``')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Fit mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Installed commit d6d4c0e\n",
    "[ud]\n",
    "# Method is `ed` or `ted`\n",
    "parameter: ud_method = \"ed\"\n",
    "# A typical choice is to estimate scales only for canonical components\n",
    "parameter: scale_only = []\n",
    "# Tolerance for change in likelihood\n",
    "parameter: ud_tol_lik = 1e-3\n",
    "input: [f'{data}'] + [f\"{mixture_components_dir}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f'{cwd}/{name}.ud.V_{vhat}.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(stringr)\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    U_scaled = list()\n",
    "    mixture_components =  c(${paths(mixture_components):r,})\n",
    "    scale_only =  c(${paths(scale_only):r,})\n",
    "    scale_idx = which(mixture_components %in% scale_only )\n",
    "    for (f in 2:length(rds_files) ) {\n",
    "        if ((f - 1) %in% scale_idx ) {\n",
    "          U_scaled = c(U_scaled, readRDS(rds_files[f]))\n",
    "        } else {\n",
    "          U = c(U, readRDS(rds_files[f]))\n",
    "        }\n",
    "    }\n",
    "    #\n",
    "    if (${\"TRUE\" if resid_cor.is_file() else \"FALSE\"}) {\n",
    "      V = readRDS(${resid_cor:r})\n",
    "    } else {\n",
    "      V = cor(dat$null.z)\n",
    "    }\n",
    "    # Fit mixture model using udr package\n",
    "    library(udr)\n",
    "    message(paste(\"Running ${ud_method.upper()} via udr package for\", length(U), \"mixture components\"))\n",
    "    f0 = ud_init(X = as.matrix(dat$strong.z), V = V, U_scaled = U_scaled, U_unconstrained = U, n_rank1=0)\n",
    "    res = ud_fit(f0, X = na.omit(f0$X), control = list(unconstrained.update = \"ed\", resid.update = 'none', scaled.update = \"fa\", maxiter=5000, tol.lik = ${ud_tol_lik}), verbose=TRUE)\n",
    "    res_ted =  ud_fit(f0, X = na.omit(f0$X), control = list(unconstrained.update = \"ted \", resid.update = 'none', scaled.update = \"fa\", maxiter=5000, tol.lik = ${ud_tol_lik}), verbose=TRUE)\n",
    "\n",
    "    saveRDS(list(U=res$U, w=res$w, loglik=res$loglik), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ted]\n",
    "# Method is `ed` or `ted`\n",
    "parameter: ud_method = \"ed\"\n",
    "# A typical choice is to estimate scales only for canonical components\n",
    "parameter: scale_only = []\n",
    "# Tolerance for change in likelihood\n",
    "parameter: ud_tol_lik = 1e-3\n",
    "input: [f'{data}'] + [f\"{mixture_components_dir}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f'{cwd}/{name}.ted.V_{vhat}.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '10G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(stringr)\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    U_scaled = list()\n",
    "    mixture_components =  c(${paths(mixture_components):r,})\n",
    "    scale_only =  c(${paths(scale_only):r,})\n",
    "    scale_idx = which(mixture_components %in% scale_only )\n",
    "    for (f in 2:length(rds_files) ) {\n",
    "        if ((f - 1) %in% scale_idx ) {\n",
    "          U_scaled = c(U_scaled, readRDS(rds_files[f]))\n",
    "        } else {\n",
    "          U = c(U, readRDS(rds_files[f]))\n",
    "        }\n",
    "    }\n",
    "    #\n",
    "    if (${\"TRUE\" if resid_cor.is_file() else \"FALSE\"}) {\n",
    "      V = readRDS(${resid_cor:r})\n",
    "    } else {\n",
    "      V = cor(dat$null.z)\n",
    "    }\n",
    "    # Fit mixture model using udr package\n",
    "    library(udr)\n",
    "    message(paste(\"Running ${ud_method.upper()} via udr package for\", length(U), \"mixture components\"))\n",
    "    f0 = ud_init(X = as.matrix(dat$strong.z), V = V, U_scaled = U_scaled, U_unconstrained = U, n_rank1=0)\n",
    "    res = ud_fit(f0, X = na.omit(f0$X), control = list(unconstrained.update = \"ed\", resid.update = 'none', scaled.update = \"fa\", maxiter=5000, tol.lik = ${ud_tol_lik}), verbose=TRUE)\n",
    "    res_ted =  ud_fit(f0, X = na.omit(f0$X), control = list(unconstrained.update = \"ted \", resid.update = 'none', scaled.update = \"fa\", maxiter=5000, tol.lik = ${ud_tol_lik}), verbose=TRUE)\n",
    "\n",
    "    saveRDS(list(U=res$U, w=res$w, loglik=res$loglik), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ed_bovy]\n",
    "parameter: ed_tol = 1e-6\n",
    "input: [f'{data}'] + [f\"{mixture_components_dir}/{name}.{m}.rds\" for m in mixture_components]\n",
    "output: f'{cwd}/{name}.ed_bovy.V_{vhat}.rds'\n",
    "task: trunk_workers = 1, walltime = '36h', trunk_size = 1, mem = '40G', cores = 4, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    rds_files = c(${_input:r,})\n",
    "    dat = readRDS(rds_files[1])\n",
    "    U = list(XtX = dat$XtX)\n",
    "    for (f in rds_files[2:length(rds_files)]) U = c(U, readRDS(f))\n",
    "    if (${\"TRUE\" if resid_cor.is_file() else \"FALSE\"}) {\n",
    "      V = readRDS(${resid_cor:r})\n",
    "    } else {\n",
    "      V = cor(dat$null.z)\n",
    "    }\n",
    "    # Fit mixture model using ED code by J. Bovy\n",
    "    mash_data = mashr::mash_set_data(dat$strong.z, V=V)\n",
    "    message(paste(\"Running ED via J. Bovy's code for\", length(U), \"mixture components\"))\n",
    "    res = mashr:::bovy_wrapper(mash_data, U, logfile=${_output:nr}, tol = ${ed_tol})\n",
    "    saveRDS(list(U=res$Ulist, w=res$pi, loglik=scan(\"${_output:n}_loglike.log\")), ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Plot patterns of sharing\n",
    "\n",
    "This is a simple utility function that takes the output from the pipeline above and make some heatmap to show major patterns of multivariate effects. The plots will be ordered by their mixture weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plot_U]\n",
    "parameter: model_data = path\n",
    "# number of components to show\n",
    "parameter: max_comp = -1\n",
    "# whether or not to convert to correlation\n",
    "parameter: to_cor = False\n",
    "parameter: tol = \"1E-6\"\n",
    "parameter: remove_label = False\n",
    "parameter: name = \"\"\n",
    "input: model_data\n",
    "output: f'{cwd:a}/{_input:bn}{(\"_\" + name.replace(\"$\", \"_\")) if name != \"\" else \"\"}.pdf'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    library(reshape2)\n",
    "    library(ggplot2)\n",
    "    plot_sharing = function(X, col = 'black', to_cor=FALSE, title=\"\", remove_names=F) {\n",
    "        clrs <- colorRampPalette(rev(c(\"#D73027\",\"#FC8D59\",\"#FEE090\",\"#FFFFBF\",\n",
    "            \"#E0F3F8\",\"#91BFDB\",\"#4575B4\")))(128)\n",
    "        if (to_cor) lat <- cov2cor(X)\n",
    "        else lat = X/max(diag(X))\n",
    "        lat[lower.tri(lat)] <- NA\n",
    "        n <- nrow(lat)\n",
    "        if (remove_names) {\n",
    "            colnames(lat) = paste('t',1:n, sep = '')\n",
    "            rownames(lat) = paste('t',1:n, sep = '')\n",
    "        }\n",
    "        melted_cormat <- melt(lat[n:1,], na.rm = TRUE)\n",
    "        p = ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+\n",
    "            geom_tile(color = \"white\")+ggtitle(title) + \n",
    "            scale_fill_gradientn(colors = clrs, limit = c(-1,1), space = \"Lab\") +\n",
    "            theme_minimal()+ \n",
    "            coord_fixed() +\n",
    "            theme(axis.title.x = element_blank(),\n",
    "                  axis.title.y = element_blank(),\n",
    "                  axis.text.x = element_text(color=col, size=8,angle=45,hjust=1),\n",
    "                  axis.text.y = element_text(color=rev(col), size=8),\n",
    "                  title =element_text(size=10),\n",
    "                  # panel.grid.major = element_blank(),\n",
    "                  panel.border = element_blank(),\n",
    "                  panel.background = element_blank(),\n",
    "                  axis.ticks = element_blank(),\n",
    "                  legend.justification = c(1, 0),\n",
    "                  legend.position = c(0.6, 0),\n",
    "                  legend.direction = \"horizontal\")+\n",
    "            guides(fill = guide_colorbar(title=\"\", barwidth = 7, barheight = 1,\n",
    "                   title.position = \"top\", title.hjust = 0.5))\n",
    "        if(remove_names){\n",
    "            p = p + scale_x_discrete(labels= 1:n) + scale_y_discrete(labels= n:1)\n",
    "        }\n",
    "        return(p)\n",
    "    }\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    name = \"${name}\"\n",
    "    if (name != \"\") {\n",
    "      if (is.null(dat[[name]])) stop(\"Cannot find data ${name} in ${_input}\")\n",
    "        dat = dat[[name]]\n",
    "    }\n",
    "    if (is.null(names(dat$U))) names(dat$U) = paste0(\"Comp_\", 1:length(dat$U))\n",
    "    meta = data.frame(names(dat$U), dat$w, stringsAsFactors=F)\n",
    "    colnames(meta) = c(\"U\", \"w\")\n",
    "    tol = ${tol}\n",
    "    n_comp = length(meta$U[which(meta$w>tol)])\n",
    "    meta = head(meta[order(meta[,2], decreasing = T),], ${max_comp if max_comp > 1 else \"nrow(meta)\"})\n",
    "    message(paste(n_comp, \"components out of\", length(dat$w), \"total components have weight greater than\", tol))\n",
    "    res = list()\n",
    "    for (i in 1:n_comp) {\n",
    "        title = paste(meta$U[i], \"w =\", round(meta$w[i], 6))\n",
    "        ##Handle updated udr data structure\n",
    "        if(is.list(dat$U[[meta$U[i]]])){\n",
    "          res[[i]] = plot_sharing(dat$U[[meta$U[i]]]$mat, to_cor = ${\"T\" if to_cor else \"F\"}, title=title, remove_names = ${\"TRUE\" if remove_label else \"FALSE\"})\n",
    "        } else if(is.matrix(dat$U[[meta$U[i]]])){\n",
    "          res[[i]] = plot_sharing(dat$U[[meta$U[i]]], to_cor = ${\"T\" if to_cor else \"F\"}, title=title, remove_names = ${\"TRUE\" if remove_label else \"FALSE\"})\n",
    "        }\n",
    "    }\n",
    "    unit = 4\n",
    "    n_col = 5\n",
    "    n_row = ceiling(n_comp / n_col)\n",
    "    pdf(${_output:r}, width = unit * n_col, height = unit * n_row)\n",
    "    do.call(gridExtra::grid.arrange, c(res, list(ncol = n_col, nrow = n_row, bottom = \"Data source: readRDS(${_input:br})${('$'+name) if name else ''}\")))\n",
    "    dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R"
    ],
    [
     "SoS"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
