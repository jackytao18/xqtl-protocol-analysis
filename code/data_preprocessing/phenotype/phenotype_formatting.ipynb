{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-assist",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data formatting\n",
    "\n",
    "\n",
    "This module implements a collection of workflows used to format molecular phenotype data.\n",
    "\n",
    "\n",
    "\n",
    "## Input\n",
    "The input for this workflow is the collection of data for 1 conditions as described in the readme of this git repo\n",
    "1. 1 complete residual molecular_phenotype data\n",
    "2. 1 region_list\n",
    "Both of these input can be generated by the annotation module of this pipeline\n",
    "\n",
    "## Output\n",
    "For each collection, the output is \n",
    "1. 1 lists of phenotype file (bed+index) for each chrom, suitable to be fed into both apex and tensorQTL, annotated with chrom and pos\n",
    "2. 1 lists of phenotype file (bed+index) for each gene, annotated with chrom and tss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682274a-fb11-4de5-849f-8320188cb674",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-championship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output  \\\n",
    "    --phenoFile MWE.log2cpm.mol_phe.bed.gz \\\n",
    "    --region-list MWE.region_list \\\n",
    "    --container containers/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-silence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# The filename namefor output data\n",
    "parameter: container = ''\n",
    "\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# name for the analysis output\n",
    "parameter: name= f'{phenoFile:bn}'\n",
    "# Whether the input data is named by gene_id or gene_name. By default it is gene_id, if not, please change it to gene_name\n",
    "parameter: phenotype_id_type = 'gene_id'\n",
    "gene_name_as_phenotype_id = \"gene_name\" == phenotype_id_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0a8a6-a874-4c02-b007-142d96b860fe",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Region List generation\n",
    "\n",
    "To partitioning the data by genes require a region list file which:\n",
    "\n",
    "    1. have 5 columns: chr,start,end,gene_id,gene_name\n",
    "    2. have the same gene as or less gene than that of the bed file\n",
    "    \n",
    "Input:\n",
    "\n",
    "    1. A gtf file used to generated the bed\n",
    "    2. A phenotype bed file, must have a gene_id column indicating the name of genes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913f0bd-a40e-45ff-a5d1-77b99b5752dd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[generate_region_list]\n",
    "#  gene gtf annotation table\n",
    "parameter: annotation_gtf = path\n",
    "input: phenoFile, annotation_gtf\n",
    "output: f'{cwd}/{_input[0]:bnn}.region_list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    import pandas as pd\n",
    "    import qtl.io\n",
    "    # get the five column data\n",
    "    bed_template_df_id = qtl.io.gtf_to_tss_bed(${_input[1]:r}, feature='transcript',phenotype_id = \"gene_id\" )\n",
    "    bed_template_df_name = qtl.io.gtf_to_tss_bed(${_input[1]:r}, feature='transcript',phenotype_id = \"gene_name\" )\n",
    "    bed_template_df = bed_template_df_id.merge(bed_template_df_name, on = [\"chr\",\"start\",\"end\"])\n",
    "    bed_template_df.columns = [\"#chr\",\"start\",\"end\",\"gene_id\",\"gene_name\"]\n",
    "    pheno = pd.read_csv(${_input[0]:r}, sep = \"\\t\")\n",
    "    # Retaining only the genes in the data\n",
    "    region_list = bed_template_df[bed_template_df.${phenotype_id_type}.isin(pheno.gene_id)]\n",
    "    region_list.to_csv(\"${_output}\", sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-summit",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Process of molecular phenotype file\n",
    "This workflow produce a bed+tabix file for all the molecular pheno data that are included in the region list to feed into downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-tobacco",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_1]\n",
    "# An index text file with 4 columns specifying the chr, start, end and names of regions to analyze, can be made on fly with <(zcat {phenoFile}.bed.gz | cut -f 1,2,3,4 )\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"chrom\"\n",
    "output: f'{cwd}/{name}.{_chrom}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    tabix $[_input] $[_chrom] >> $[_output:n] \n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-number",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_chrom_2]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.processed_phenotype.per_chrom.recipe'\n",
    "import pandas as pd\n",
    "chrom = [str(x).split(\".\")[-4] for x in _input]\n",
    "chrom_df = pd.DataFrame({\"#id\" : chrom ,\"#dir\" : _input})\n",
    "chrom_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-pollution",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_1]\n",
    "# An index text file with 5 columns specifying the chr, start, end and names of regions to analyze\n",
    "parameter: region_list = path\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"regions\"\n",
    "output: f'{cwd}/{name}.{_regions[3]}.{_regions[4]}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    zcat $[_input] | grep  $[_regions[3] if gene_name_as_phenotype_id else _regions[4]] >> $[_output:n]\n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-abraham",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.processed_phenotype.per_gene.recipe'\n",
    "import pandas as pd\n",
    "region_df = pd.DataFrame({\"#id\" : [x[3] for x in regions] ,\"dir\" : _input})\n",
    "region_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7494e52-0954-48a5-86ee-9a518efa3c7f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bed_filter_na]\n",
    "# Tolerance of missingness rows with missing rate larger than tol_missing will be removed,\n",
    "# with missing rate smaller than tol_missing will be mean_imputed. Say if we want to keep rows with less than 5% missing, then we use 0.05 as tol_missing.\n",
    "parameter: tol_missing = 0.05\n",
    "input: phenoFile\n",
    "output: f'{_input:nn}.filter_na.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "   library(\"dplyr\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return(mean_impute(X))\n",
    "        }  \n",
    "  \n",
    "    bed = read_delim(\"${_input}\")\n",
    "    mtx = bed[,5:ncol(bed)]%>%as.matrix\n",
    "    rownames(mtx) = bed[,4]%>%unlist()\n",
    "    tbl_filtered = filter_mtx(mtx%>%t(),${tol_missing})%>%t()%>%as_tibble(rownames = colnames(bed)[4] )\n",
    "    bed_filtered = inner_join(bed[,1:4],tbl_filtered)\n",
    "    bed_filtered%>%write_delim(${_output:n}, \"\\t\" )\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f4f3-2384-47fa-8a97-846294b7001a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_subsetting]\n",
    "parameter: region = \"chr21 chr22\"\n",
    "input: phenoFile , group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.subsetted.bam'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container\n",
    "    samtools view -b ${_input} ${region} > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0c34c-d37f-44e6-bd70-e420fd5c66f9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[bam_to_fastq]\n",
    "input: phenoFile, group_by = 1\n",
    "output: f'{cwd}/{_input:bn}.1.fastq',f'{cwd}/{_input:bn}.2.fastq'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', container=container\n",
    "    samtools sort -n ${_input} -o ${_input}.sorted.bam\n",
    "    bedtools bamtofastq -i ${_input}.sorted.bam  -fq ${_output[0]} -fq2 ${_output[1]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
